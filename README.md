# Natural Language Processing Projects

This repository provides insights and discussions on projects completed during my Natural Language Processing class. Here's an overview of the key projects discussed:

## 1. N-Gram Language Modeling and Markov Text Generation
- The `n_gram_assignment.py` script is a fundamental part of this project, focusing on implementing an n-gram language model and Markov text generator.
- Demonstrates the application of both n-grams and Markov chains for language modeling and text completion, using both deterministic and stochastic methods.
- Utilizes stupid backoff for text generation.

## 2. Part-of-Speech Tagging (POS)
- The POS tagging project involves implementing the Viterbi algorithm and Hidden Markov Models (HMMs) for effective part-of-speech tagging.
- Key components include understanding the Markov property, optimizing language models, and enhancing predictive power in natural language processing.

## 3. Gradient Descent Optimization
- The `unigram_pytorch.py` script is utilized in this project, focusing on optimizing Language Models (LMs) using Gradient Descent.
- Highlights the significance of Gradient Descent in minimizing loss, fine-tuning model parameters, and achieving efficient convergence.
- Discusses its crucial role in enhancing language models like ChatGPT.

In this repository, we delve into each project, exploring its objectives, implementations, and outcomes. The focus is on providing a concise and informative understanding of the key concepts and applications within the domain of Natural Language Processing.
